# Copyright (c) Meta Platforms, Inc. and affiliates

import sys

sys.path.append("src")
sys.path.append("./")
import os

import torch
import torch.nn.functional as F
import argparse
from get_prep_parser import get_args_parser, get_default_paths
from prep_caption import get_tarfile_path

import json, pdb

from multiprocessing import Pool
from tqdm import tqdm


# --- ä¿®å¤ 1ï¼šå®‰å…¨çš„èµ‹å€¼å‡½æ•° ---
def build_assignment(feat_dir, shard_id, assign_dir, overwrite=True):
    shard_folder = shard_id % 100
    output_fn_group = os.path.join(assign_dir, f"{shard_folder}", f'{shard_id}_assign_dist.json')
    os.makedirs(os.path.dirname(output_fn_group), exist_ok=True)

    # æ„é€ ç‰¹å¾æ–‡ä»¶è·¯å¾„
    feat_fn = os.path.join(feat_dir, f"{shard_folder}", f'{shard_id}_feat.pth')
    if not os.path.exists(feat_fn):
        # print(f"âš ï¸ [Skip] æ‰¾ä¸åˆ°ç‰¹å¾æ–‡ä»¶: {feat_fn}")
        return None

    if os.path.exists(output_fn_group) and not overwrite:
        # print(f'{output_fn_group} Written already')
        return True

    # å¼ºåˆ¶ CPU åŠ è½½
    try:
        feature = torch.load(feat_fn, map_location='cpu')
        assign = {'key': feature['filekeys'], 'image': feature['img_midx']}
        # å½’ä¸€åŒ–ç‰¹å¾
        feat_tensor = F.normalize(feature['feat'], dim=-1)

        for key, ccenter in ccenters.items():
            # è®¡ç®—è·ç¦» (CPU)
            if key[0] == 'E':  # euclidean
                # cdist å¯èƒ½éœ€è¦ float ç±»å‹ä¸€è‡´
                dist = torch.cdist(feat_tensor.float()[None], ccenter.float()[None])[0]
                min_dist, assign_tensor = dist.min(dim=-1)
                # min_dist = min_dist.numpy().tolist() # å¯é€‰ä¿å­˜è·ç¦»
            elif key[0] == 'C':  # cosine
                sim = torch.mm(feat_tensor.float(), ccenter.T.float())
                max_sim, assign_tensor = sim.max(dim=-1)
                # min_dist = (1.0 - max_sim).numpy().tolist()

            # ä¿å­˜åˆ†é…ç»“æœ
            assign[key] = {'assign': assign_tensor.numpy().tolist()}

        with open(output_fn_group, 'w') as json_file:
            json.dump(assign, json_file)
        # print(f'âœ… å·²ç”Ÿæˆ: {shard_id}')
        return assign
    except Exception as e:
        print(f"âŒ å¤„ç† {shard_id} å¤±è´¥: {e}")
        return None


def func(args, _start, _end):
    # --- ä¿®å¤ 2ï¼šå­è¿›ç¨‹ç‹¬ç«‹è·¯å¾„è§£æ ---
    wds_dir = os.path.dirname(args.root)

    # --- ä¿®å¤ 3ï¼šå­è¿›ç¨‹ç‹¬ç«‹åŠ è½½èšç±»ä¸­å¿ƒ ---
    global ccenters
    ccenters = {}
    for dist_type in ['euclidean']:
        for cm in [args.cm, ]:
            path = os.path.join(args.ccenter_dir, dist_type, f'F{cm}.pth')
            if os.path.exists(path):
                key = '{}{}'.format(dist_type[0].upper(), args.cm)
                # å¼ºåˆ¶åŠ è½½åˆ° CPU
                ccenters[key] = torch.load(path, map_location='cpu')['center']
                if 'cos' in dist_type:
                    ccenters[key] = F.normalize(ccenters[key], dim=-1)
            else:
                print(f"âŒ å­è¿›ç¨‹æ‰¾ä¸åˆ°èšç±»ä¸­å¿ƒæ–‡ä»¶: {path}")

    missing_shards = []

    # ç¡®å®šè¿­ä»£èŒƒå›´
    if isinstance(_start, list):
        warc_iter = _start
    else:
        # å¦‚æœæ˜¯èŒƒå›´ï¼Œç”¨ tqdm æ˜¾ç¤ºè¿›åº¦
        warc_iter = tqdm(range(_start, _end))

    for idx, shard_id in enumerate(warc_iter):
        # è¿™é‡Œçš„æ£€æŸ¥å…¶å®æ˜¯éå¿…é¡»çš„ï¼Œå› ä¸ºæˆ‘ä»¬è¦æ ¹æ® feature æ–‡ä»¶ç”Ÿæˆ assignment
        # ä½†ä¿ç•™åŸé€»è¾‘
        wds_fn = get_tarfile_path(wds_dir, shard_id)
        # å…¼å®¹æ€§æ£€æŸ¥ï¼šå¦‚æœ get_tarfile_path æ‰¾ä¸åˆ°ï¼Œæˆ‘ä»¬æš‚æ—¶å¿½ç•¥ï¼Œç›´æ¥å°è¯•æ‰¾ feature
        # if not os.path.exists(wds_fn):
        #    continue

        status = build_assignment(
            args.feature_dir, shard_id, args.cassign_dir, overwrite=False,
        )
        if status:
            pass
        elif status is None:
            missing_shards.append(shard_id)
        # else:
        #    raise ValueError('No Implementation Error')

    return missing_shards


def main(args):
    print("âœ… è¿›å…¥ main å‡½æ•°")

    # --- ä¿®å¤ 4ï¼šæ‰“å°è°ƒè¯•ä¿¡æ¯ ---
    print(f"ğŸ” ç›®æ ‡èŒƒå›´: {args.tar_init} -> {args.tar_end}")
    print(f"ğŸ” èšç±»æ•° (cm): {args.cm}")
    print(f"ğŸ” ç‰¹å¾ç›®å½•: {args.feature_dir}")
    print(f"ğŸ” èšç±»ä¸­å¿ƒç›®å½•: {args.ccenter_dir}")

    # è®¡ç®—ä»»åŠ¡åˆ†é…
    shard_ids = [[] for _ in range(args.num_threads)]
    # +1 æ˜¯å› ä¸º range æ˜¯å·¦é—­å³å¼€ï¼Œæˆ‘ä»¬è¦åŒ…å«æœ€åä¸€ä¸ªæ–‡ä»¶
    real_end = args.tar_end + 1

    for shard_id in range(args.tar_init, real_end):
        group_offset = shard_id % args.num_threads
        shard_ids[group_offset].append(shard_id)

    print(f"ğŸ“‹ ä»»åŠ¡åˆ†é…ç¤ºä¾‹ (çº¿ç¨‹0): {shard_ids[0][:10]}...")

    starts = shard_ids
    ends = [None for _ in range(len(starts))]
    argss = [args for _ in range(len(starts))]

    # è¿™é‡Œçš„ wds_dir åœ¨ä¸»è¿›ç¨‹å…¶å®æ²¡ç”¨ï¼Œä¸»è¦çœ‹ func é‡Œçš„
    global wds_dir
    wds_dir = os.path.dirname(args.root)

    # å¯åŠ¨å¤šè¿›ç¨‹
    with Pool(len(starts)) as p:
        results = p.starmap(
            func,
            zip(
                argss,
                starts,
                ends,
            ),
        )

    all_results = []
    for result in results:
        all_results.extend(result)
    print("missing npy count:", len(all_results))


if __name__ == '__main__':
    parser = argparse.ArgumentParser('Clustering evaluation', parents=[get_args_parser()])
    config = parser.parse_args()

    # åŠ è½½é»˜è®¤è·¯å¾„
    if config.dataset in get_default_paths():
        paths = get_default_paths()[config.dataset]
        config.root = paths['root']
        config.feature_dir = paths['feature']
        config.cassign_dir = paths['assign']
        config.ccenter_dir = paths['cluster']

    # --- ä¿®å¤ 5ï¼šå…³é”®ï¼è§£ææ–‡ä»¶èŒƒå›´ ---
    # å¦‚æœæ²¡æŒ‡å®š tar_endï¼Œå°è¯•ä» root è·¯å¾„è§£æ {00..67}
    if config.tar_end == -1:
        try:
            base = os.path.basename(config.root)
            if '{' in base and '}' in base:
                parts = base.split("{")[1].split("}")[0].split("..")
                config.tar_end = int(parts[1])
                print(f"ğŸ” è‡ªåŠ¨è§£æ tar_end = {config.tar_end}")
            else:
                print("âš ï¸ è­¦å‘Š: æ— æ³•ä»è·¯å¾„è§£æ tar_endï¼Œå°†é»˜è®¤ä¸º -1 (ä¸æ‰§è¡Œ)")
        except Exception as e:
            print(f"âŒ è§£æè·¯å¾„èŒƒå›´å¤±è´¥: {e}")

    config.num_threads = 8  # ç¨å¾®é™ä½çº¿ç¨‹æ•°ï¼Œé˜²æ­¢å¡é¡¿

    os.makedirs(config.cassign_dir, exist_ok=True)

    print("ğŸš€ å¼€å§‹è¿è¡Œä¸“å®¶æŒ‡æ´¾...")
    main(config)